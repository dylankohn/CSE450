{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "starter_bikes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA0HPVmIBT4C"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "df_train = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StiU5QcPPxqQ"
      },
      "source": [
        "df_train['dteday'] = pd.to_datetime(df_train['dteday'])\n",
        "\n",
        "if 'total_rentals' not in df_train.columns:\n",
        "    df_train['total_rentals'] = df_train['casual'] + df_train['registered']\n",
        "\n",
        "features = ['hr', 'temp_c', 'feels_like_c', 'hum', 'windspeed',\n",
        "            'weathersit', 'season', 'holiday', 'workingday']\n",
        "X = df_train[features]\n",
        "y = df_train['total_rentals']"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALLMN63FPyEQ",
        "outputId": "063e74e5-bd7f-40bc-ad25-ac3d35cd13b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnGBwGVZPyyh",
        "outputId": "fe9a250c-88b9-4693-eaf6-5affd83f2bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 119952.8438 - mae: 248.8902 - val_loss: 75974.6016 - val_mae: 200.8599\n",
            "Epoch 2/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 75773.9219 - mae: 199.1148 - val_loss: 69712.9688 - val_mae: 190.9967\n",
            "Epoch 3/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 66321.4453 - mae: 181.2816 - val_loss: 58047.7695 - val_mae: 165.5894\n",
            "Epoch 4/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 57088.3164 - mae: 164.9005 - val_loss: 53183.8711 - val_mae: 158.9070\n",
            "Epoch 5/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 51075.0273 - mae: 152.3264 - val_loss: 49487.5273 - val_mae: 148.5623\n",
            "Epoch 6/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 49515.3125 - mae: 146.2532 - val_loss: 47110.6094 - val_mae: 140.5990\n",
            "Epoch 7/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 47250.0000 - mae: 141.2040 - val_loss: 45455.6094 - val_mae: 138.4104\n",
            "Epoch 8/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 45417.4766 - mae: 137.4694 - val_loss: 43890.4805 - val_mae: 134.8323\n",
            "Epoch 9/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 44113.4883 - mae: 135.6114 - val_loss: 41357.8750 - val_mae: 131.6230\n",
            "Epoch 10/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 41391.1992 - mae: 130.6830 - val_loss: 38808.3867 - val_mae: 127.3068\n",
            "Epoch 11/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 38999.9531 - mae: 127.3229 - val_loss: 36988.7461 - val_mae: 124.9275\n",
            "Epoch 12/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 36995.8320 - mae: 123.7068 - val_loss: 35642.6914 - val_mae: 121.0381\n",
            "Epoch 13/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 34990.2930 - mae: 120.3833 - val_loss: 33716.7852 - val_mae: 119.1516\n",
            "Epoch 14/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 33821.6680 - mae: 117.9477 - val_loss: 32437.2812 - val_mae: 117.1392\n",
            "Epoch 15/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 32923.2383 - mae: 116.7398 - val_loss: 34517.5586 - val_mae: 117.4585\n",
            "Epoch 16/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 32610.6914 - mae: 115.5558 - val_loss: 30904.5000 - val_mae: 113.8274\n",
            "Epoch 17/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 31198.2539 - mae: 113.2167 - val_loss: 30085.0898 - val_mae: 111.6815\n",
            "Epoch 18/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 31187.5977 - mae: 113.5967 - val_loss: 31224.9941 - val_mae: 115.6912\n",
            "Epoch 19/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 29856.8730 - mae: 111.1115 - val_loss: 28894.8496 - val_mae: 110.4490\n",
            "Epoch 20/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 30098.5469 - mae: 111.5349 - val_loss: 30012.0918 - val_mae: 110.8240\n",
            "Epoch 21/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 29420.6641 - mae: 109.8382 - val_loss: 29148.8652 - val_mae: 110.3795\n",
            "Epoch 22/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 28831.8750 - mae: 109.1853 - val_loss: 28668.8340 - val_mae: 108.8835\n",
            "Epoch 23/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 29062.4453 - mae: 109.9122 - val_loss: 29452.3379 - val_mae: 110.4350\n",
            "Epoch 24/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 28766.3105 - mae: 109.1795 - val_loss: 29743.4824 - val_mae: 110.5811\n",
            "Epoch 25/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 28526.2168 - mae: 108.6338 - val_loss: 27704.9492 - val_mae: 107.8212\n",
            "Epoch 26/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 28936.6367 - mae: 109.3376 - val_loss: 28150.3730 - val_mae: 109.0542\n",
            "Epoch 27/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 27734.1758 - mae: 106.9602 - val_loss: 27313.1602 - val_mae: 106.0500\n",
            "Epoch 28/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 28136.7227 - mae: 107.8743 - val_loss: 28608.7871 - val_mae: 110.4602\n",
            "Epoch 29/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 27532.7734 - mae: 106.5226 - val_loss: 26902.7910 - val_mae: 105.3258\n",
            "Epoch 30/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 27314.5996 - mae: 105.9429 - val_loss: 30273.3008 - val_mae: 112.2447\n",
            "Epoch 31/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 27442.4238 - mae: 106.0466 - val_loss: 26763.4707 - val_mae: 105.2778\n",
            "Epoch 32/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 27044.7012 - mae: 105.5622 - val_loss: 27092.1719 - val_mae: 106.2499\n",
            "Epoch 33/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 27520.1270 - mae: 106.4642 - val_loss: 26921.1094 - val_mae: 105.4692\n",
            "Epoch 34/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 27366.3809 - mae: 105.7047 - val_loss: 27136.6504 - val_mae: 105.7472\n",
            "Epoch 35/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 27092.2500 - mae: 104.9090 - val_loss: 36629.4648 - val_mae: 119.8296\n",
            "Epoch 36/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 27131.3418 - mae: 105.3420 - val_loss: 27122.0195 - val_mae: 105.2346\n",
            "Epoch 37/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 27128.2109 - mae: 105.2511 - val_loss: 27179.1465 - val_mae: 105.4811\n",
            "Epoch 38/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26694.9824 - mae: 104.4267 - val_loss: 27341.7656 - val_mae: 105.1104\n",
            "Epoch 39/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 27267.8008 - mae: 105.5184 - val_loss: 28917.1973 - val_mae: 108.8191\n",
            "Epoch 40/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26726.5938 - mae: 104.6197 - val_loss: 26114.0176 - val_mae: 103.6871\n",
            "Epoch 41/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 26451.4531 - mae: 104.1681 - val_loss: 27275.5508 - val_mae: 104.5300\n",
            "Epoch 42/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26794.7227 - mae: 104.7385 - val_loss: 26890.0039 - val_mae: 105.8920\n",
            "Epoch 43/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 26521.2832 - mae: 103.9936 - val_loss: 26645.9336 - val_mae: 104.5760\n",
            "Epoch 44/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26708.2930 - mae: 104.2526 - val_loss: 26919.1484 - val_mae: 105.4219\n",
            "Epoch 45/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 26546.1582 - mae: 104.1387 - val_loss: 26597.8457 - val_mae: 104.2949\n",
            "Epoch 46/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26653.0176 - mae: 103.8476 - val_loss: 26534.2344 - val_mae: 103.9580\n",
            "Epoch 47/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 26554.3379 - mae: 103.8351 - val_loss: 26120.7773 - val_mae: 102.9857\n",
            "Epoch 48/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 26576.4668 - mae: 104.1005 - val_loss: 26949.2910 - val_mae: 104.3041\n",
            "Epoch 49/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26976.3691 - mae: 104.5173 - val_loss: 26276.1602 - val_mae: 103.1616\n",
            "Epoch 50/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 26621.2402 - mae: 103.8640 - val_loss: 25898.4434 - val_mae: 103.2714\n",
            "Epoch 51/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 26838.7637 - mae: 104.2799 - val_loss: 26682.8125 - val_mae: 104.7676\n",
            "Epoch 52/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 26187.2715 - mae: 103.1596 - val_loss: 27653.3398 - val_mae: 106.0401\n",
            "Epoch 53/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 26615.0254 - mae: 103.8692 - val_loss: 26307.3965 - val_mae: 103.8162\n",
            "Epoch 54/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26296.7051 - mae: 102.9768 - val_loss: 26219.6621 - val_mae: 103.9941\n",
            "Epoch 55/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 26660.1074 - mae: 104.1014 - val_loss: 26742.5430 - val_mae: 104.1628\n",
            "Epoch 56/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26397.3730 - mae: 103.3792 - val_loss: 27222.9277 - val_mae: 104.4561\n",
            "Epoch 57/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 26324.3457 - mae: 103.0761 - val_loss: 25604.3066 - val_mae: 102.9221\n",
            "Epoch 58/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 26027.8145 - mae: 102.6217 - val_loss: 27619.7637 - val_mae: 105.8663\n",
            "Epoch 59/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 26041.5664 - mae: 102.7534 - val_loss: 26120.1484 - val_mae: 103.2154\n",
            "Epoch 60/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26198.9551 - mae: 102.9172 - val_loss: 26212.7734 - val_mae: 103.1905\n",
            "Epoch 61/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 25830.6387 - mae: 102.3196 - val_loss: 25402.1641 - val_mae: 101.8189\n",
            "Epoch 62/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26039.4648 - mae: 103.0505 - val_loss: 25526.2070 - val_mae: 101.3896\n",
            "Epoch 63/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 26030.2227 - mae: 102.5792 - val_loss: 25947.5117 - val_mae: 102.6813\n",
            "Epoch 64/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 25789.6328 - mae: 102.3483 - val_loss: 26529.1641 - val_mae: 104.6288\n",
            "Epoch 65/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26372.6074 - mae: 103.4282 - val_loss: 26043.6699 - val_mae: 102.8625\n",
            "Epoch 66/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 25567.0684 - mae: 101.7880 - val_loss: 25850.9062 - val_mae: 102.5260\n",
            "Epoch 67/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 26373.6113 - mae: 103.3899 - val_loss: 27124.3164 - val_mae: 104.8995\n",
            "Epoch 68/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 26013.4062 - mae: 102.4322 - val_loss: 25907.9609 - val_mae: 102.7918\n",
            "Epoch 69/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 26200.1680 - mae: 102.4672 - val_loss: 25388.4434 - val_mae: 102.1753\n",
            "Epoch 70/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 26276.5488 - mae: 102.8600 - val_loss: 25475.5430 - val_mae: 101.3306\n",
            "Epoch 71/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 25833.4180 - mae: 102.2820 - val_loss: 25753.2363 - val_mae: 102.5328\n",
            "Epoch 72/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 25263.1328 - mae: 101.1999 - val_loss: 25725.0176 - val_mae: 101.8233\n",
            "Epoch 73/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 25555.3086 - mae: 101.9666 - val_loss: 25429.9844 - val_mae: 101.3857\n",
            "Epoch 74/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 25859.2383 - mae: 102.4710 - val_loss: 25319.4258 - val_mae: 101.4643\n",
            "Epoch 75/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 25828.0098 - mae: 102.3123 - val_loss: 25520.6797 - val_mae: 102.1167\n",
            "Epoch 76/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 26037.1777 - mae: 102.5453 - val_loss: 26279.3867 - val_mae: 102.9651\n",
            "Epoch 77/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 25694.6094 - mae: 102.1016 - val_loss: 25943.2422 - val_mae: 102.1300\n",
            "Epoch 78/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 25553.9961 - mae: 101.5167 - val_loss: 25302.6309 - val_mae: 101.0126\n",
            "Epoch 79/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 25470.6543 - mae: 101.4253 - val_loss: 27653.1797 - val_mae: 106.0925\n",
            "Epoch 80/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 25837.2285 - mae: 102.0618 - val_loss: 25934.2852 - val_mae: 103.0653\n",
            "Epoch 81/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 25615.4043 - mae: 101.5148 - val_loss: 26091.3984 - val_mae: 102.3555\n",
            "Epoch 82/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 25953.2441 - mae: 102.2081 - val_loss: 25652.0273 - val_mae: 101.3444\n",
            "Epoch 83/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 25316.4453 - mae: 101.1423 - val_loss: 25332.2949 - val_mae: 102.0609\n",
            "Epoch 84/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 25745.5723 - mae: 101.9300 - val_loss: 25463.6855 - val_mae: 101.0804\n",
            "Epoch 85/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 25696.7305 - mae: 101.9461 - val_loss: 25332.1016 - val_mae: 100.6763\n",
            "Epoch 86/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 25710.6074 - mae: 101.7459 - val_loss: 25912.2988 - val_mae: 102.5929\n",
            "Epoch 87/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 25595.1719 - mae: 101.3696 - val_loss: 25803.5234 - val_mae: 102.0578\n",
            "Epoch 88/100\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 25557.6602 - mae: 101.3594 - val_loss: 25721.5723 - val_mae: 101.1434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVSfaqgKPzE2"
      },
      "source": [
        "df_december = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes_december.csv')\n",
        "df_december['dteday'] = pd.to_datetime(df_december['dteday'])\n",
        "\n",
        "X_december = df_december[features]\n",
        "X_december_scaled = scaler.transform(X_december)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_december_scaled)\n",
        "df_december['predicted_total'] = predictions.astype(int)\n",
        "\n",
        "daily_predictions = df_december.groupby('dteday')['predicted_total'].sum().reset_index()\n",
        "daily_predictions.columns = ['date', 'predicted_total_rentals']"
      ],
      "metadata": {
        "id": "JTVRZzkHBpmj",
        "outputId": "34d6e4df-dae7-4a22-b2b0-a0bb3204ab91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daily_predictions.to_csv('daily_bike_predictions.csv', index=False)\n",
        "\n",
        "print(f\"\\nPredictions saved to daily_bike_predictions.csv\")\n",
        "print(f\"Predicted {len(daily_predictions)} days in December\")\n",
        "print(daily_predictions.head(10))"
      ],
      "metadata": {
        "id": "8YRublwkBrf1",
        "outputId": "e81d1d08-4c42-4379-8fb6-c954b189ff5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions saved to daily_bike_predictions.csv\n",
            "Predicted 61 days in December\n",
            "        date  predicted_total_rentals\n",
            "0 2023-11-01                     6927\n",
            "1 2023-11-02                     7473\n",
            "2 2023-11-03                     8407\n",
            "3 2023-11-04                     9346\n",
            "4 2023-11-05                    10443\n",
            "5 2023-11-06                     9206\n",
            "6 2023-11-07                    11112\n",
            "7 2023-11-08                     9402\n",
            "8 2023-11-09                     9452\n",
            "9 2023-11-10                     3942\n"
          ]
        }
      ]
    }
  ]
}